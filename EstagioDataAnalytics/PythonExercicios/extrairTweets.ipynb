{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keys\n",
    "twitter_keys = {\n",
    "'consumer_key': 'zx4jf9sgeik8rILRxgQn6bd9M',\n",
    "'consumer_secret': '8KGl8fVcMFtPf2tfuobBkG5crh1gv148SqNnrYYPIf842HNR96',\n",
    "'access_token_key': '715999776987344896-DxRXVFURrjGm8XBVk3yCnkD5sCF66Rv',\n",
    "'access_token_secret': 'Rkk8XOhN1rnsSIoclNQxzXqIaZyB64dY8QQlOguAgj6bd'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85980bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "#Configura acesso a API do twitter\n",
    "auth = tweepy.OAuthHandler(twitter_keys['consumer_key'],twitter_keys['consumer_secret'])\n",
    "auth.set_access_token(twitter_keys['access_token_key'],twitter_keys['access_token_secret'])\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#configurando bucket\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id='AKIASRYWVMNZBNYI76FR',\n",
    "    aws_secret_access_key='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',\n",
    ")\n",
    "s3 = session.resource('s3')\n",
    "\n",
    "#Coletando os tweets\n",
    "search_words = \"presidente\"\n",
    "public_tweets = tweepy.Cursor(api.search_tweets,q=search_words,lang=\"pt-br\").items(115)\n",
    "\n",
    "#Salvando tweets em lista\n",
    "tweets = []\n",
    "tweets_aux =[]\n",
    "\n",
    "for tweet in public_tweets:\n",
    "    tweets_aux.append(tweet.id)\n",
    "    tweets_aux.append(tweet.text)\n",
    "    tweets_aux.append(tweet.created_at)\n",
    "\n",
    "    tweets.append(tweets_aux)\n",
    "    tweets_aux=[]\n",
    "\n",
    "#Quantos arquivos JSON preciso\n",
    "qtdUploads = (len(tweets)//100)+1\n",
    "print(\"{} tweets restantes.\".format(len(tweets)))\n",
    "\n",
    "#define funcao para upload de arquivos para o S3\n",
    "def uploadTweets(lista):\n",
    "    df = pd.DataFrame(lista, columns =['id', 'tweet_text','tweet_date'])\n",
    "    horario_mais_antigo=str(df[\"tweet_date\"].max())[:19]\n",
    "    df['tweet_date'] = df['tweet_date'].astype(str).str[:10]\n",
    "    horario_mais_antigo=horario_mais_antigo.replace(\":\", \"-\")\n",
    "    df.to_json(\"output/{}.json\".format(horario_mais_antigo),orient='records')\n",
    "    s3.meta.client.upload_file(Filename='output/{}.json'.format(horario_mais_antigo), Bucket='rawdesafioxpto', Key='rawdata/{}.json'.format(horario_mais_antigo))\n",
    "        \n",
    "    print(\"Arquivo salvo com {} tweets!\".format(len(lista)))\n",
    "    print(\"{} tweets restantes.\".format(len(tweets)))\n",
    "        \n",
    "    lista=[]\n",
    "\n",
    "#Faz upload dos arquivos\n",
    "lista100tt=[]\n",
    "for _ in range(0,qtdUploads):\n",
    "    if len(tweets) >= 100:\n",
    "        for _ in range(0,100):\n",
    "            lista100tt.append(tweets[0])\n",
    "            tweets.pop(0)\n",
    "    \n",
    "        uploadTweets(lista100tt)\n",
    "        lista100tt=[]\n",
    "        \n",
    "        \n",
    "    elif len(tweets) < 100 and len(tweets) >=1:\n",
    "        for _ in range(0,len(tweets)):\n",
    "            lista100tt.append(tweets[0])\n",
    "            tweets.pop(0)\n",
    "    \n",
    "        uploadTweets(lista100tt)\n",
    "        lista100tt=[]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#GLUE VERSION\n",
    "###################################\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "\n",
    "spark_context = SparkContext.getOrCreate()\n",
    "glue_context = GlueContext(spark_context)\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "\n",
    "#Parameters\n",
    "s3_write_path = \"s3://refdesafioxpto/write\"\n",
    "\n",
    "\n",
    "#Log starting time\n",
    "dt_start = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(\"Start time:\", dt_start)\n",
    "\n",
    "#Ler arquivo json\n",
    "#df = spark.read.option(\"encoding\", \"UTF-8\").option(\"header\", \"true\").json(\"s3://rawdesafioxpto/rawdata\")\n",
    "df = spark.read.option(\"header\", \"true\").json(\"s3://rawdesafioxpto/rawdata\")\n",
    "\n",
    "#funcao para definir o sentimento do texto\n",
    "happy = [\":)\",\":}\",\":]\",\":D\",\":p\",\":-)\",\";-)\",\":P\",\";)\"]\n",
    "sad = [\":(\",\":{\",\":[\",\":-(\",\";-(\",\";(\",\":/\"]\n",
    "\n",
    "def buscaPositivo(palavra):\n",
    "    for i in happy:\n",
    "        if i in palavra and all(ch in i for ch in palavra):\n",
    "            return True\n",
    "    if palavra in happy:\n",
    "        return True\n",
    "    \n",
    "def buscaNegativo(palavra):\n",
    "    for i in sad:\n",
    "        if i in palavra and all(ch in i for ch in palavra):\n",
    "            return True\n",
    "    if palavra in sad:\n",
    "        return True\n",
    "\n",
    "    \n",
    "def buscarSentimento(string):\n",
    "    string_splitada = string.split()\n",
    "    \n",
    "    for i in string_splitada:\n",
    "        if buscaPositivo(i) == True:\n",
    "            sentimento=\"Positivo\"\n",
    "            break\n",
    "        elif buscaNegativo(i) == True:\n",
    "            sentimento=\"Negativo\"\n",
    "            break\n",
    "        else:\n",
    "            sentimento=\"Neutro\"\n",
    "        \n",
    "    return sentimento\n",
    "\n",
    "def buscarSimbolo(string):\n",
    "    string_splitada = string.split()\n",
    "    \n",
    "    for i in string_splitada:\n",
    "        if buscaPositivo(i) == True:\n",
    "            simbolo=i\n",
    "            break\n",
    "        elif buscaNegativo(i) == True:\n",
    "            simbolo=i\n",
    "            break\n",
    "        else:\n",
    "            simbolo=\"\"\n",
    "        \n",
    "    return simbolo\n",
    "\n",
    "#registrar funcoes UDF\n",
    "buscarSentimentoUDF = spark.udf.register(\"buscarSentimentoUDF\", buscarSentimento)\n",
    "buscarSimboloUDF = spark.udf.register(\"buscarSimboloUDF\", buscarSimbolo)\n",
    "buscaPositivoUDF = spark.udf.register(\"buscaPositivoUDF\", buscaPositivo)\n",
    "buscaNegativoUDF = spark.udf.register(\"buscaNegativoUDF\", buscaNegativo)\n",
    "\n",
    "\n",
    "#muda o data type da coluna tweet_date\n",
    "df = df.select(col(\"id\"),col(\"tweet_text\"),to_date(col(\"tweet_date\"),\"yyyy-MM-dd\").alias(\"tweet_date\"))\n",
    "\n",
    "#adiciona coluna sentimento\n",
    "df = df.withColumn(\"sentimento\", buscarSentimentoUDF(col(\"tweet_text\")))\n",
    "\n",
    "#adiciona coluna simbolo\n",
    "df = df.withColumn(\"simbolo\", buscarSimboloUDF(col(\"tweet_text\")))\n",
    "\n",
    "df = df\\\n",
    "    .withColumn('year',\n",
    "                 date_format(col(\"tweet_date\"), \"yyyy\"))\\\n",
    "    .withColumn('month',\n",
    "                 date_format(col(\"tweet_date\"), \"MM\"))\\\n",
    "    .withColumn('day',\n",
    "                 date_format(col(\"tweet_date\"), \"dd\"))\n",
    "\n",
    "\n",
    "#Convert back to dynamic frame\n",
    "dynamic_frame_write = DynamicFrame.fromDF(df, glue_context, \"dynamic_frame_write\")\n",
    " \n",
    "#Write data back to S3\n",
    "glue_context.write_dynamic_frame.from_options(\n",
    "frame = dynamic_frame_write,\n",
    "connection_type = \"s3\",\n",
    "connection_options = {\n",
    "\"path\": s3_write_path,\n",
    "#Here you could create S3 prefixes according to a values in specified columns\n",
    "\"partitionKeys\": [\"year\", \"month\", \"day\"]\n",
    "},\n",
    "format = \"glueparquet\"\n",
    ")\n",
    " \n",
    "#Log end time\n",
    "dt_end = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(\"End time:\", dt_end)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "eb4c129129849fb9f4ef58e77e01b32557b6e1484a03db6be9951f4068ff54a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
